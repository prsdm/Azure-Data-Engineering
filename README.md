# Azure-Data-Engineering!
Task 
The primary objective of this project is to design and implement a data engineering pipeline 
that can ingest, process, store, and visualize data from various sources, including
databases, third-party APIs, web scraping, and internal data files.
## Pipeline
![ss](https://github.com/Prsd17/Azure-Data-Engineering/assets/93597510/9f88cfb8-3956-4871-9b83-e94002567eab)
 
### 1. Data Ingestion: 
* Data from multiple sources is ingested into Azure Data Lake Gen 2. 
* Azure Data Factory is used to schedule and coordinate data ingestion activities. 
### 2. Data Transformation: 
* Azure Databricks is employed for data cleaning, transformation, and 
enrichment. 
* Databricks notebooks are developed to ensure data quality and prepare it for 
downstream analytics. 
### 3. Data Storage: 
* Cleaned and transformed data is stored in Azure Data Lake Gen 2 for easy 
accessibility. 
* The hierarchical structure of Data Lake aids efficient data organization. 
### 4. Data Warehousing: 
* Azure Synapse Analytics is utilized for data warehousing and advanced 
analytics. 
* Data is curated and aggregated within Synapse Analytics for complex queries. 
### 5. Report Development: 
* Power BI connects to Azure Synapse Analytics to create interactive dashboards 
and reports. 
* These reports provide actionable insights into sales performance, inventory 
levels, customer behaviour, and other key performance indicators (KPIs).


## Project Video
https://github.com/Prsd17/Azure-Data-Engineering/assets/93597510/9d8070df-7f1c-4f70-8f78-86181f1fd5e8



## Dashboard
![Screenshot 2023-09-29 132539](https://github.com/Prsd17/Azure-Data-Engineering/assets/93597510/40695cf8-7da9-4938-a36c-0757a14c0de9)


